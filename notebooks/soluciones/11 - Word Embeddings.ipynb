{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "\n",
    "Los Word Embeddings son aquellas técnicas y modelos de lenguaje que permiten mapear palabras a vectores de valores continuos. Durante el entrenamiento de dichos vectores se buscará que capturen la información semántica de las palabras.\n",
    "\n",
    "<img src=https://miro.medium.com/max/1280/1*OEmWDt4eztOcm5pr2QbxfA.png widt=500px>\n",
    "\n",
    "Gracias a que los vectores tienen información sobre la semántica, mediante operaciones vectoriales podemos encontrar palabras (o documentos) que tienen un significado similar.\n",
    "\n",
    "La idea principal de este tipo de modelos es que **palabras que aparecen en contextos similares tienen semánticas similares**. **Concepto de sustituibilidad**.\n",
    "\n",
    "**Aquellas palabras que semánticamente son similares tendrán - idealmente - vectores-palabra cercanos entre sí.**\n",
    "\n",
    "Existen multitud de modelos, en esta sesión veremos solo algunas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "El modelo más famoso de word embeddings. Inventado por [Tomas Mikolov en 2013 en Google](https://arxiv.org/pdf/1310.4546.pdf)\n",
    "\n",
    "https://radimrehurek.com/gensim/models/word2vec.html\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "Algunos de los hiperparámetros que deberemos tener en cuenta y configuraremos:\n",
    "\n",
    "- size: dimensionalidad de las palabras vector\n",
    "- window: ventana para obtener el contexto de cada palabra. Se mide en número de palabras máximo entre la palabra actual y la palabra a predecir\n",
    "- min_count: frecuencia mínima de aparición de una palabra para que sea considerada en el entrenamiento\n",
    "- sg: algoritmo escogido. 1 para Skip-Gram, 0 para CBOW\n",
    "- hs: si = 1, se utiliza una softmax jerárquica. Si = 0, y negative != 0, se emplea negative sampling\n",
    "- negative: si = 0, no se usa negative sampling. Si es > 0, se usará negative sampling. El valor indica el número de \"palabras ruidosas\" se incluirán (usual entre 5-20 para datasets pequeños, entre 2-5 para datasets grandes)\n",
    "\n",
    "### Noción de contexto\n",
    "\n",
    "<img src=https://docs.chainer.org/en/v4.0.0b2/_images/center_context_word.png width=450px>\n",
    "\n",
    "## Atributos\n",
    "\n",
    "- wv: word vectors, contiene el mapeo entre palabras y vectores (embeddings)\n",
    "- vocabulary: vocabulario (o diccionario) del modelo\n",
    "\n",
    "\n",
    "## Negative sampling\n",
    "\n",
    "Cuando se trabaja en NLP el tamaño del vocabulario suele tener una cardinalidad enorme. Esto afecta a los modelos de lenguaje a la hora de predecir aquellas palabras que, aunque correctas, no son demasiado frecuentes.\n",
    "\n",
    "Además, contextos muy comunes (como los que podrían ser aquellos en los que se encuentran muchas stop words) hacen que el entrenamiento sea lento. Se emplea, por tanto, para reducir la carga computacional al problema.\n",
    "\n",
    "La solución que se propone - e implementa - Word2Vec es que cada palabra tenga una determinada probabilidad de ser eliminada del training set. Dicha probabilidad estará relacionada con la frecuencia de repetición de dicha palabra.\n",
    "\n",
    "\n",
    "## Arquitecturas\n",
    "\n",
    "Existen dos arquitecturas de este modelo: CBOW y Skip Gram.\n",
    "\n",
    "\n",
    "#### CBOW (Continuous Bag of Words)\n",
    "\n",
    "Durante el entrenamiento, el modelo tratará de **predecir la palabra actual** dado el contexto en el que se encuentre. La capa de entrada contendrá las palabras-contexto y la de salida será la palabra actual (o palabra a predecir). La capa intermedia tendrá una dimension igual al número de dimensiones en el que queremos representar la palabra actual a la salida.\n",
    "\n",
    "<img src=https://miro.medium.com/max/1104/0*CCsrTAjN80MqswXG width=400px>\n",
    "\n",
    "\n",
    "#### Skip Gram\n",
    "\n",
    "Durante el entrenamiento, el modelo tratará de predecir **el contexto (palabras-contexto)** a una palabra dada. La capa de entrada contendrá la palabra actual y la de salida serán las palabras contexto. La capa intermedia es análoga a la presente en la arquitectura CBOW.\n",
    "\n",
    "<img src=https://miro.medium.com/max/1280/0*Ta3qx5CQsrJloyCA.png width=300px>\n",
    "\n",
    "### ¿Cuál es mejor?\n",
    "\n",
    "En general, depende. CBOW, al haber sido entrenado para predecir una palabra dado un contexto, será algo mejor _rellenando huecos_, aunque eso puede significar que palabras correctas pero menos comunes no aparezcan como resultado algunas veces. Skip Gram, en cambio, debería ser mejor infiriendo relaciones más concretas en contextos similares (por ejemplo, \"me gusta el color verde\" y \"me encanta el color azul\", y la diferencia en la intensidad del sentimiento expresado).\n",
    "\n",
    "Si atendemos a los comentarios de Mikolov:\n",
    "\n",
    "- Skip-gram: funciona bien con conjuntos de datos pequeños, representando bien incluso palabras o frases extrañas (poco comunes)\n",
    "- CBOW: entrenamiento varias veces más rápido, su performance mejor para aquellas palabras más frecuentes que el resto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palabras más similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sim_words(word, model1, model2):\n",
    "    query = \"Most similar to {}\".format(word) \n",
    "    print(query)\n",
    "    print(\"-\"*len(query))\n",
    "    for (sim1, sim2) in zip(model1.wv.most_similar(word), model2.wv.most_similar(word)):\n",
    "        print(\"{}:{}{:.3f}{}{}:{}{:.3f}\".format(sim1[0],\n",
    "                                               \" \"*(20-len(sim1[0])), \n",
    "                                               sim1[1], \n",
    "                                               \" \"*10, \n",
    "                                               sim2[0],\n",
    "                                               \" \"*(20-len(sim2[0])),\n",
    "                                               sim2[1]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = LineSentence('../../datasets/spanish_news_corpus_doc.txt', limit=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_params = {\n",
    "    'sg': 1,\n",
    "    'size': 300,\n",
    "    'min_count': 5,\n",
    "    'window': 5,\n",
    "    'hs': 0,\n",
    "    'negative': 20,\n",
    "    'workers': 4\n",
    "}\n",
    "\n",
    "cbow_params = {\n",
    "    'sg': 0,\n",
    "    'size': 300,\n",
    "    'min_count': 5,\n",
    "    'window': 5,\n",
    "    'hs': 0,\n",
    "    'negative': 20,\n",
    "    'workers': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializamos los objetos Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip Gram\n",
    "w2v_sg = Word2Vec(**sg_params)\n",
    "\n",
    "# CBOW\n",
    "w2v_cbow = Word2Vec(**cbow_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construímos el vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Skip Gram\n",
    "w2v_sg.build_vocab(corpus)\n",
    "\n",
    "# CBOW\n",
    "w2v_cbow.build_vocab(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario compuesto por 2576 palabras\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulario compuesto por {} palabras'.format(len(w2v_sg.wv.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario compuesto por 2576 palabras\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulario compuesto por {} palabras'.format(len(w2v_cbow.wv.vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamos los pesos de los embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2047796, 3906600)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skip Gram\n",
    "w2v_sg.train(sentences=corpus, total_examples=w2v_sg.corpus_count, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048520, 3906600)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CBOW\n",
    "w2v_cbow.train(sentences=corpus, total_examples=w2v_cbow.corpus_count, epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardamos los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_sg.save('../../data/w2v_sg_d300_mc5_w5.pkl')\n",
    "w2v_cbow.save('../../data/w2v_cbow_d300_mc5_w5.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algunos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to elecciones\n",
      "--------------------------\n",
      "generales:           0.833          generales:           0.747\n",
      "forzar:              0.747          forzar:              0.644\n",
      "cs:                  0.708          cs:                  0.598\n",
      "unidas:              0.687          johnson:             0.564\n",
      "próximas:            0.684          próximas:            0.556\n",
      "cuentas:             0.682          sumar:               0.546\n",
      "funciones:           0.680          apoyos:              0.540\n",
      "sánchez:             0.680          moción:              0.536\n",
      "apoyos:              0.670          pedir:               0.532\n",
      "presentar:           0.668          rechaza:             0.525\n",
      "\n",
      "\n",
      "Most similar to botín\n",
      "---------------------\n",
      "concurso:            0.890          ana:                 0.805\n",
      "endesa:              0.865          jesús:               0.623\n",
      "abascal:             0.845          presidenta:          0.609\n",
      "álvarez:             0.844          álvarez:             0.607\n",
      "vicepresidente:      0.839          policía:             0.603\n",
      "ana:                 0.831          gobernador:          0.599\n",
      "mañueco:             0.820          vicepresidente:      0.594\n",
      "policía:             0.814          próxima:             0.583\n",
      "jesús:               0.813          ferrovial:           0.577\n",
      "sesiones:            0.812          ex:                  0.570\n",
      "\n",
      "\n",
      "Most similar to sánchez\n",
      "-----------------------\n",
      "pedro:               0.939          pedro:               0.711\n",
      "unidas:              0.889          iglesias:            0.580\n",
      "rivera:              0.878          rivera:              0.568\n",
      "cs:                  0.852          negociar:            0.549\n",
      "rechaza:             0.836          unidas:              0.543\n",
      "iglesias:            0.824          naranja:             0.538\n",
      "investidura:         0.823          cs:                  0.526\n",
      "funciones:           0.806          defendido:           0.521\n",
      "naranja:             0.806          investidura:         0.509\n",
      "inste:               0.801          lamentado:           0.504\n",
      "\n",
      "\n",
      "Most similar to impeachment\n",
      "---------------------------\n",
      "donald:              0.887          donald:              0.620\n",
      "mantuvo:             0.843          confirma:            0.604\n",
      "trump:               0.836          trump:               0.594\n",
      "inste:               0.820          optimismo:           0.587\n",
      "pedro:               0.802          exmarido:            0.560\n",
      "catalán:             0.793          boris:               0.541\n",
      "ex:                  0.788          inste:               0.533\n",
      "fifa:                0.788          ue:                  0.529\n",
      "relaciones:          0.778          ex:                  0.529\n",
      "político:            0.776          fifa:                0.528\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_sim_words('elecciones', w2v_cbow, w2v_sg)\n",
    "print_sim_words('botín', w2v_cbow, w2v_sg)\n",
    "print_sim_words('sánchez', w2v_cbow, w2v_sg)\n",
    "print_sim_words('impeachment', w2v_cbow, w2v_sg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palabras fuera del vocabulario (OOV Words)\n",
    "\n",
    "Los embeddings calculados a nivel de palabra no devolverán un vector para aquellos tokens que no hayan guardado en su vocabulario. Una vez que los vectores palabra han sido aprendidos, aquellas palabras que no han sido aprendidas durante el entrenamiento no tendrán representación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'asereje' in w2v_cbow.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'asereje' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-f76be785519f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw2v_cbow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'asereje'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'asereje' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "w2v_cbow.wv.most_similar('asereje')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas estrategias para lidiar con palabras OOV:\n",
    "- Asignar un vector que siga una distribución aleatoria uniforme. P. ej.:\n",
    "`unk = np.random.uniform(-np.var(w2v.wv.vectors), np.var(w2v.wv.vectors), w2v.wv.vector_size)`\n",
    "- Reemplazar por un token especial, conocido y distinto del resto, (`<unk>`) y entrenar los embeddings\n",
    "- Reemplazar por un token especial, conocido y disinto del resto, y añadir información extra. P. ej.: `<unk_noun>` o `<unk_verb>`\n",
    "- Utilizar modelos que no sean a nivel de palabra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización: Bonus\n",
    "\n",
    "[Enlace](https://anvaka.github.io/pm/#/galaxy/word2vec-wiki?cx=-16179&cy=-1641&cz=4313&lx=0.3194&ly=-0.5230&lz=-0.4110&lw=0.6749&ml=300&s=1.75&l=1&v=d50_clean)\n",
    "\n",
    "<img src=https://empresas.blogthinkbig.com/wp-content/uploads/2019/06/embeddings_galaxy.png width=650px>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
