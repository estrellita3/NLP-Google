{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy\n",
    "\n",
    "spaCy es otra librería open source en Python para NLP.\n",
    "\n",
    "La diferencia fundamental entre NLTK y spaCy es que el primero es muy cómodo para aprender e iniciarse mientras que el segundo está pensado para productizar.\n",
    "\n",
    "Gensim, otra librería, la veremos más adelante cuando estudiemos Topic Modeling y Word Embeddings.\n",
    "\n",
    "Documentación de spaCy: https://spacy.io/\n",
    "\n",
    "La filosofía de trabajo en spaCy es que si existen una serie de algoritmos que solucionan un problema, dar la solución al problema con un único. Además, su funcionamiento se basa en la construcción de pipelines.\n",
    "\n",
    "\n",
    "<img src=https://i.imgur.com/nD7ut2U.jpg>\n",
    "\n",
    "¿Qué capacidades (modelos) linguísticas nos ofrece spaCy?\n",
    "\n",
    "<img src=https://i.imgur.com/lGcL6lx.jpg>\n",
    "\n",
    "Es decir, de spaCy podremos sacar siempre que queramos tokens, pos tags, árboles de dependencia, o entidades nombradas. Incluye también modelos de word embeddings (que veremos con más detalle en sesiones posteriores)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://spacy.io/architecture-bcdfffe5c0b9f221a2f6607f96ca0e4a.svg width=550px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de spaCy\n",
    "\n",
    "Modelos pre-entrenados para diferentes idiomas y con diferentes corpus. Pueden ser descargados de diferentes maneras, tanto descarga directa, como con pip.\n",
    "\n",
    "Link: https://spacy.io/usage/models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download es_core_news_sm\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz --no-deps\n",
    "# pip install https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.3.0/es_core_news_sm-2.3.0.tar.gz#egg=es_core_news_sm==2.3.0 --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U spacy download es_core_news_sm\n",
    "# !pip install -U spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# import es_core_news_sm\n",
    "# import en_core_web_sm\n",
    "\n",
    "# nlp_es = es_core_news_sm.load()\n",
    "# nlp_en = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Modelo \"pequeño\" entrenado con noticias en castellano\n",
    "# https://spacy.io/models/es\n",
    "nlp_es = spacy.load('es_core_news_sm')\n",
    "\n",
    "# Modelo \"pequeño\" entrenado con página\n",
    "# https://spacy.io/models/en\n",
    "nlp_en = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline del modelo por defecto\n",
    "nlp_es.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines en spaCy:\n",
    "https://spacy.io/usage/processing-pipelines\n",
    "\n",
    "<img src=https://d33wubrfki0l68.cloudfront.net/16b2ccafeefd6d547171afa23f9ac62f159e353d/48b91/pipeline-7a14d4edd18f3edfee8f34393bff2992.svg width=700px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Mi nombre es Carlos y vivo en Madrid. Hoy es martes 8 de junio'\n",
    "doc = nlp_es(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mi nombre es Carlos y vivo en Madrid. Hoy es martes 8 de junio\n"
     ]
    }
   ],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase 0    Mi nombre es Carlos y vivo en Madrid.\n",
      "Frase 1    Hoy  \n",
      "Frase 2    es martes 8 de junio\n"
     ]
    }
   ],
   "source": [
    "for idx, sent in enumerate(doc.sents):\n",
    "    print('Frase {0:5}{1:5}'.format(str(idx), sent.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 0    Mi   \n",
      "Token 1    nombre\n",
      "Token 2    es   \n",
      "Token 3    Carlos\n",
      "Token 4    y    \n",
      "Token 5    vivo \n",
      "Token 6    en   \n",
      "Token 7    Madrid\n",
      "Token 8    .    \n",
      "Token 9    Hoy  \n",
      "Token 10   es   \n",
      "Token 11   martes\n",
      "Token 12   8    \n",
      "Token 13   de   \n",
      "Token 14   junio\n"
     ]
    }
   ],
   "source": [
    "for idx, token in enumerate(doc):\n",
    "    print('Token {0:5}{1:5}'.format(str(idx), token.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token     Shape     is_alpha\n",
      "Mi        Xx        True \n",
      "nombre    xxxx      True \n",
      "es        xx        True \n",
      "Carlos    Xxxxx     True \n",
      "y         x         True \n",
      "vivo      xxxx      True \n",
      "en        xx        True \n",
      "Madrid    Xxxxx     True \n",
      ".         .         False\n",
      "Hoy       Xxx       True \n",
      "es        xx        True \n",
      "martes    xxxx      True \n",
      "8         d         False\n",
      "de        xx        True \n",
      "junio     xxxx      True \n"
     ]
    }
   ],
   "source": [
    "print('{0:10}{1:10}{2:5}'.format('Token', 'Shape', 'is_alpha'))\n",
    "for token in doc:\n",
    "    print('{0:10}{1:10}{2:5}'.format(token.text, token.shape_, str(token.is_alpha)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalización de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tiene', 'tuyo', 'unos', 'lugar', 'vaya', 'general', 'ningún', 'ésos', 'pueda', 'usted', 'alguna', 'raras', 'sean', 'detrás', 'éstos', 'mío', 'buenas', 'he', 'entre', 'quienes']\n"
     ]
    }
   ],
   "source": [
    "# Eliminar stop words\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "\n",
    "print(list(STOP_WORDS)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['frase', 'a', 'eliminar', 'stopwords']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_text_1 = 'Soy una frase de ejemplo de la cual vamos a eliminar los stopwords'\n",
    "[word for word in ex_text_1.lower().split() if word not in STOP_WORDS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debate: ¿Pensáis que, en general, se deben filtrar los stopwords?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gusta', 'canción']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_text_2 = 'No me gusta esta canción'\n",
    "[word for word in ex_text_2.lower().split() if word not in STOP_WORDS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech tagging\n",
    "\n",
    "El PoS Tagging es una técnica **fundamental** en NLP que consiste en etiquetar cada palabra de un documento en su correspondiente categría gramatical.\n",
    "\n",
    "<img src=https://blog.aaronccwong.com/assets/images/bigram-hmm/pos-title.jpg width=650px>\n",
    "\n",
    "¿Utilidad? Muchísima:\n",
    "\n",
    "- Posibilidad de encontrar los adjetivos / sustantivos /adverbios más comunes\n",
    "- _Ayuda_ a Lemmatizers al desambiguar entre palabras\n",
    "- Grafos en los que los nodos son entidades y verbos. Posibilidad de analizar relaciones entre entidades -> Pintar ejemplo\n",
    "- Posibles features (la distribución de categorías no siempre es homogénea en función del contexto)\n",
    "\n",
    "Podríamos hacer un algoritmo que mirara verbos entre otras entidades, como nombres o adjetivos, y que fuera el verbo quien decidiera que relación tienen esas entidades. Eso se suele hacer para crear bases de datos de grafos, donde cada nodo es una entidad, y entre entidades hay relaciones.\n",
    "\n",
    "Veamos algún ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atributos (https://spacy.io/api/token#attributes):\n",
    "- pos_: tipo de palabra (sustantivo, verbo, adjetivo, etc)\n",
    "- tag_: tipo de palabra especificando más atributos\n",
    "- dep_: relación de dependencia sintáctica\n",
    "\n",
    "Explicación de los términos:\n",
    "https://github.com/explosion/spaCy/blob/master/spacy/glossary.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mi nombre es Carlos y vivo en Madrid. Hoy es martes 8 de junio"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token     pos       \n",
      "Mi        DET       \n",
      "nombre    NOUN      \n",
      "es        AUX       \n",
      "Carlos    PROPN     \n",
      "y         CCONJ     \n",
      "vivo      VERB      \n",
      "en        ADP       \n",
      "Madrid    PROPN     \n",
      ".         PUNCT     \n",
      "Hoy       ADV       \n",
      "es        AUX       \n",
      "martes    NOUN      \n",
      "8         NUM       \n",
      "de        ADP       \n",
      "junio     NOUN      \n"
     ]
    }
   ],
   "source": [
    "print('{0:10}{1:10}'.format('Token', 'pos'))\n",
    "for idx, token in enumerate(doc):\n",
    "    print('{0:10}{1:10}'.format(token.text, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token     tag       \n",
      "Mi        DET       \n",
      "nombre    NOUN      \n",
      "es        AUX       \n",
      "Carlos    PROPN     \n",
      "y         CCONJ     \n",
      "vivo      VERB      \n",
      "en        ADP       \n",
      "Madrid    PROPN     \n",
      ".         PUNCT     \n",
      "Hoy       ADV       \n",
      "es        AUX       \n",
      "martes    NOUN      \n",
      "8         NUM       \n",
      "de        ADP       \n",
      "junio     NOUN      \n"
     ]
    }
   ],
   "source": [
    "print('{0:10}{1:10}'.format('Token', 'tag'))\n",
    "for idx, token in enumerate(doc):\n",
    "    print('{0:10}{1:10}'.format(token.text, token.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token     dep       Meaning   \n",
      "Mi        det       determiner\n",
      "nombre    nsubj     nominal subject\n",
      "es        cop       copula    \n",
      "Carlos    ROOT      None      \n",
      "y         cc        coordinating conjunction\n",
      "vivo      conj      conjunct  \n",
      "en        case      case marking\n",
      "Madrid    nmod      modifier of nominal\n",
      ".         punct     punctuation\n",
      "Hoy       ROOT      None      \n",
      "es        cop       copula    \n",
      "martes    ROOT      None      \n",
      "8         compound  compound  \n",
      "de        case      case marking\n",
      "junio     compound  compound  \n"
     ]
    }
   ],
   "source": [
    "print('{0:10}{1:10}{2:10}'.format('Token', 'dep', 'Meaning'))\n",
    "for idx, token in enumerate(doc):\n",
    "    print('{0:10}{1:10}{2:10}'.format(token.text, token.dep_, str(spacy.explain(token.dep_))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencia sintáctica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"es\" id=\"ecfa9293e7734a1bb91f4b3b31e1e344-0\" class=\"displacy\" width=\"1450\" height=\"337.0\" direction=\"ltr\" style=\"max-width: none; height: 337.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Mi</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">nombre</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">es</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">Carlos</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">y</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">vivo</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">en</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Madrid.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">Hoy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">es</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1050\">martes</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1050\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">8</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">de</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1350\">junio</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1350\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-0\" stroke-width=\"2px\" d=\"M70,202.0 C70,152.0 135.0,152.0 135.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,204.0 L62,192.0 78,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-1\" stroke-width=\"2px\" d=\"M170,202.0 C170,102.0 340.0,102.0 340.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M170,204.0 L162,192.0 178,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-2\" stroke-width=\"2px\" d=\"M270,202.0 C270,152.0 335.0,152.0 335.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cop</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M270,204.0 L262,192.0 278,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-3\" stroke-width=\"2px\" d=\"M470,202.0 C470,152.0 535.0,152.0 535.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M470,204.0 L462,192.0 478,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-4\" stroke-width=\"2px\" d=\"M370,202.0 C370,102.0 540.0,102.0 540.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M540.0,204.0 L548.0,192.0 532.0,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-5\" stroke-width=\"2px\" d=\"M670,202.0 C670,152.0 735.0,152.0 735.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M670,204.0 L662,192.0 678,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-6\" stroke-width=\"2px\" d=\"M370,202.0 C370,2.0 750.0,2.0 750.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,204.0 L758.0,192.0 742.0,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-7\" stroke-width=\"2px\" d=\"M970,202.0 C970,152.0 1035.0,152.0 1035.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cop</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M970,204.0 L962,192.0 978,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-8\" stroke-width=\"2px\" d=\"M1070,202.0 C1070,152.0 1135.0,152.0 1135.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1135.0,204.0 L1143.0,192.0 1127.0,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-9\" stroke-width=\"2px\" d=\"M1270,202.0 C1270,152.0 1335.0,152.0 1335.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270,204.0 L1262,192.0 1278,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-10\" stroke-width=\"2px\" d=\"M1070,202.0 C1070,52.0 1345.0,52.0 1345.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecfa9293e7734a1bb91f4b3b31e1e344-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1345.0,204.0 L1353.0,192.0 1337.0,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de entidades nombradas (NER)\n",
    "\n",
    "El reconocimiento de entidades nombradas (Named Entity Recognition, NER, por sus siglas en inglés) trata de detectar posibles entidades nombradas y, posteriormente, clasificarlas entre un conjunto de categorías predefinidas.\n",
    "\n",
    "Ejemplos de entidades nombradas: nombres de personas, lugares, cantidades, empresas...\n",
    "\n",
    "Pero, ¿qué es exactamente una _entidad nombrada_? Según definió Saul Kripke * (filósofo y lógico) son - o deberían ser - todas aquellas entidades para las cuales existe uno - o más de uno - designador rígido. Es decir, dicha palabra / expresión se refiere a la misma cosa / entidad con independencia del contexto.\n",
    "\n",
    "<img src=https://hyscore.io/wp-content/uploads/2019/03/illustration_named_entity_recognition-1024x486-1.jpg width=700px>\n",
    "\n",
    "El rendimiento de los NER varía mucho en función del idioma en el que han sido entrenados. El rendimiento que se comienza a obtener (debido principalmente al uso de modelos de embeddings contextuales) supera al de un ser humano.\n",
    "\n",
    "Un enlace intersante: https://primer.ai/blog/a-new-state-of-the-art-for-named-entity-recognition/\n",
    "\n",
    "* _El nombrar y la necesidad_ (Saul Kripke), 1980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jim\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " compró 300 acciones de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Acme Corp\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ". en 2006</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_ner_1 = nlp_es('Jim compró 300 acciones de Acme Corp. en 2006')\n",
    "displacy.render(doc_ner_1, style='ent', jupyter=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Peter bought \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    300\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " shares of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Acme Corp.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2006\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_ner_2 = nlp_en('Peter bought 300 shares of Acme Corp. in 2006')\n",
    "displacy.render(doc_ner_2, style='ent', jupyter=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I heard that \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Paris\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hilton\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " stayed at the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hilton\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Paris\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_ner_2 = nlp_en('I heard that Paris Hilton stayed at the Hilton in Paris')\n",
    "displacy.render(doc_ner_2, style='ent', jupyter=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token     Entity Label\n",
      "Jim       PER       \n",
      "Acme Corp PER       \n"
     ]
    }
   ],
   "source": [
    "print('{0:10}{1:10}'.format('Token', 'Entity Label'))\n",
    "for entity in doc_ner_1.ents:\n",
    "    print('{0:10}{1:10}'.format(entity.text, entity.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token     Entity Label\n",
      "Paris     GPE       \n",
      "Hilton    GPE       \n",
      "Hilton    GPE       \n",
      "Paris     GPE       \n"
     ]
    }
   ],
   "source": [
    "print('{0:10}{1:10}'.format('Token', 'Entity Label'))\n",
    "for entity in doc_ner_2.ents:\n",
    "    print('{0:10}{1:10}'.format(entity.text, entity.label_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "\n",
    "Técnica de normalización de textos que busca reducir las palabras a su raíz (lemma).\n",
    "\n",
    "Muy utilizado para reducir la cardinalidad del vocabulario asociando para diferentes formas flexionadas un único token ('entreno', 'entrenarás', 'entrenaría' -> 'entrenar').\n",
    "\n",
    "Aunque muy utilizados en motores de búsqueda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{0:10}{1:10}{2:10}'.format('Token', 'Lemma', 'PoS Tag'))\n",
    "for idx, token in enumerate(doc):\n",
    "    print('{0:10}{1:10}{2:10}'.format(token.text, token.lemma_, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 2\n",
      "Token     Lemma     PoS Tag   \n",
      "comer     comer     VERB      \n",
      "comiendo  comer     VERB      \n",
      "comieron  comer     VERB      \n",
      "comedor   comedor   NOUN      \n",
      "comeré    comeré    ADJ       \n",
      "comerá    comer     VERB      \n",
      "comerás   comerás   ADP       \n",
      "\n",
      "Text 3\n",
      "Token     Lemma     PoS Tag   \n",
      "comerás   comerás   VERB      \n"
     ]
    }
   ],
   "source": [
    "text_2 = 'comer comiendo comieron comedor comeré comerá comerás'\n",
    "text_3 = 'comerás'\n",
    "doc_2 = nlp_es(text_2)\n",
    "doc_3 = nlp_es(text_3)\n",
    "\n",
    "\n",
    "print('Text 2')\n",
    "print('{0:10}{1:10}{2:10}'.format('Token', 'Lemma', 'PoS Tag'))\n",
    "for idx, token in enumerate(doc_2):\n",
    "    print('{0:10}{1:10}{2:10}'.format(token.text, token.lemma_, token.pos_))\n",
    "\n",
    "print('\\nText 3')\n",
    "print('{0:10}{1:10}{2:10}'.format('Token', 'Lemma', 'PoS Tag'))\n",
    "for idx, token in enumerate(doc_3):\n",
    "    print('{0:10}{1:10}{2:10}'.format(token.text, token.lemma_, token.pos_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization vs Stemming\n",
    "\n",
    "Ambas tienen como objetivo reducir las palabras a su raíz léxica.\n",
    "\n",
    "- **Lemmatization**:\n",
    "\n",
    "    Tiene en consideración el análisis morfológico de las palabras. Son necesarios diccionarios completos de formas flexionadas y raíces (lemmas).\n",
    "    \n",
    "    A veces es necesario desambiguar. P. ej.: \"planta\" (planta vs plantar)\n",
    "\n",
    "<img src=https://blog.bitext.com/hs-fs/hubfs/lemma_v2.png width=500px>\n",
    "\n",
    "- **Stemming**:\n",
    "    \n",
    "    Algoritmos que mediante heurísticos / reglas tratan de reducir las palabras a una posible raíz (stem) mediante la eliminación de algunos prefijos y sufijos. Más sencillo que un lemmatizer\n",
    "    \n",
    "    No hay garantía de que el resultado sea una palabra real.\n",
    "    \n",
    "    El algoritmo más utilizado en Inglés es el de Porter que consiste en 5 fases de reducción de la palabra aplicadas de manera secuencial.\n",
    "    <img src=https://blog.bitext.com/hs-fs/hubfs/stemming_v2.png width=250px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similitud\n",
    "\n",
    "Si trabajamos con los _small models_ (SM) en lugar de los _large models_ (LM), en lugar de trabajar con _word vectors_ estaremos trabajando con _context-sensitive tensors_.\n",
    "\n",
    "No os preocupéis, los modelos de _word embeddings_ los estudiaremos con mucho más detalle en próximas sesiones :D\n",
    "\n",
    "Como adelanto, en el caso de trabajar con los primeros (word vectors) siempre tendremos el mismo vector para el mismo token. Si trabajamos con los segundos (context-sensitive tensors) el vector del token estará determinado por su contexto (el resto de tokens que le rodean).\n",
    "\n",
    "Aunque el concepto de similitud lo veremos más adelante, como adelanto, conocer que con spaCy es posible calcular lo _parecidos_ o _distintos_ que son dos tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip3 install https://github.com/explosion/spacy-models/releases/download/es_core_news_md-2.3.0/es_core_news_md-2.3.0.tar.gz#egg=es_core_news_md==2.3.0 --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !python3 -m spacy download es_core_news_md\n",
    "import spacy\n",
    "nlp_es_md = spacy.load('es_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between word 1 and word 2: 0.743638\n",
      "Similarity between word 1 and word 3: 0.382572\n",
      "Similarity between word 2 and word 3: 0.442991\n"
     ]
    }
   ],
   "source": [
    "word_1 = nlp_es_md('verde')\n",
    "word_2 = nlp_es_md('azul')\n",
    "word_3 = nlp_es_md('mariposa')\n",
    "\n",
    "print('Similarity between word {} and word {}: {:0.6f}'.format(1, 2, word_1.similarity(word_2)))\n",
    "print('Similarity between word {} and word {}: {:0.6f}'.format(1, 3, word_1.similarity(word_3)))\n",
    "print('Similarity between word {} and word {}: {:0.6f}'.format(2, 3, word_2.similarity(word_3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between sent 1 and sent 2: 0.967595\n",
      "Similarity between sent 1 and sent 3: 0.651385\n",
      "Similarity between sent 2 and sent 3: 0.653034\n"
     ]
    }
   ],
   "source": [
    "sent_1 = nlp_es_md('me gusta el color verde')\n",
    "sent_2 = nlp_es_md('me gusta el azul')\n",
    "sent_3 = nlp_es_md('me gusta la mariposa')\n",
    "\n",
    "print('Similarity between sent {} and sent {}: {:0.6f}'.format(1, 2, sent_1.similarity(sent_2)))\n",
    "print('Similarity between sent {} and sent {}: {:0.6f}'.format(1, 3, sent_1.similarity(sent_3)))\n",
    "print('Similarity between sent {} and sent {}: {:0.6f}'.format(2, 3, sent_2.similarity(sent_3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El Universo de spaCy\n",
    "\n",
    "Diferentes recursos (paquetes, plugins, extensiones, etc) desarrollados por o para spaCy.\n",
    "\n",
    "https://spacy.io/universe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
