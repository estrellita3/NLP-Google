{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A36BI9SPO3LTC8</td>\n",
       "      <td>B0023ZQDEC</td>\n",
       "      <td>Gerbera Daisy</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Not a good fit for me. Much too big. I didn't ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Not good for me</td>\n",
       "      <td>1360972800</td>\n",
       "      <td>02 16, 2013</td>\n",
       "      <td>0</td>\n",
       "      <td>clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL1WTXQJCKT8X</td>\n",
       "      <td>B00HWF7KPY</td>\n",
       "      <td>Granny \"Joyous-soul\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>good fit- not to thin- love the less thicker  ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Surprised</td>\n",
       "      <td>1403308800</td>\n",
       "      <td>06 21, 2014</td>\n",
       "      <td>0</td>\n",
       "      <td>clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2QOT4L1QFYYIW</td>\n",
       "      <td>B003VFGW76</td>\n",
       "      <td>lu shenglan</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Quality is very goodMy husband liked itThe nex...</td>\n",
       "      <td>5</td>\n",
       "      <td>Quality is very good</td>\n",
       "      <td>1387152000</td>\n",
       "      <td>12 16, 2013</td>\n",
       "      <td>0</td>\n",
       "      <td>clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2KQUKZ4X13BI0</td>\n",
       "      <td>B001CGW432</td>\n",
       "      <td>musica_al</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>I like wearing bungee style slip on shoes.  Th...</td>\n",
       "      <td>5</td>\n",
       "      <td>Just what I wanted</td>\n",
       "      <td>1305331200</td>\n",
       "      <td>05 14, 2011</td>\n",
       "      <td>0</td>\n",
       "      <td>clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATJOVP7P6JRPU</td>\n",
       "      <td>B005OBWI3W</td>\n",
       "      <td>T.W. Connell</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I thought the bracelet would be packaged in a ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Nice product poor packaging</td>\n",
       "      <td>1355356800</td>\n",
       "      <td>12 13, 2012</td>\n",
       "      <td>0</td>\n",
       "      <td>clothing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin          reviewerName helpful  \\\n",
       "0  A36BI9SPO3LTC8  B0023ZQDEC         Gerbera Daisy  [0, 0]   \n",
       "1   AL1WTXQJCKT8X  B00HWF7KPY  Granny \"Joyous-soul\"  [0, 0]   \n",
       "2  A2QOT4L1QFYYIW  B003VFGW76           lu shenglan  [0, 0]   \n",
       "3  A2KQUKZ4X13BI0  B001CGW432             musica_al  [2, 2]   \n",
       "4   ATJOVP7P6JRPU  B005OBWI3W          T.W. Connell  [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Not a good fit for me. Much too big. I didn't ...        3   \n",
       "1  good fit- not to thin- love the less thicker  ...        5   \n",
       "2  Quality is very goodMy husband liked itThe nex...        5   \n",
       "3  I like wearing bungee style slip on shoes.  Th...        5   \n",
       "4  I thought the bracelet would be packaged in a ...        3   \n",
       "\n",
       "                       summary  unixReviewTime   reviewTime  sentiment  \\\n",
       "0              Not good for me      1360972800  02 16, 2013          0   \n",
       "1                    Surprised      1403308800  06 21, 2014          0   \n",
       "2         Quality is very good      1387152000  12 16, 2013          0   \n",
       "3           Just what I wanted      1305331200  05 14, 2011          0   \n",
       "4  Nice product poor packaging      1355356800  12 13, 2012          0   \n",
       "\n",
       "   category  \n",
       "0  clothing  \n",
       "1  clothing  \n",
       "2  clothing  \n",
       "3  clothing  \n",
       "4  clothing  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminamos valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['reviewText', 'sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función de preprocesado de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementamos una función de preprocesado de texto que nos permitirá estandarizar el formato de las reviews a la entrada y reducir la cardinalidad del vocabulario. Se realizan los siguientes pasos:\n",
    "- Eliminar tildes\n",
    "- Eliminar símbolos\n",
    "- Eliminar todo carácter que no sea una letra\n",
    "- Elimar stopwords\n",
    "- Lemmatization en base a diccionario de token-lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_normalization(sentence):\n",
    "    sentence = unicodedata.normalize('NFKD', sentence).lower().encode('ascii', errors='ignore').decode('utf-8')\n",
    "    sentence = re.sub(' +', ' ', ' '.join([word if word.isalpha() else '' for word in sentence.split()])).strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(sentence, sw_list):\n",
    "    sentence = ' '.join([word for word in sentence.split() if word not in sw_list])\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemmas_dict(data_path, lemmas_dict_file):\n",
    "    lemmas_dict = {}\n",
    "    with open(os.path.join(data_path, lemmas_dict_file), 'r') as f:\n",
    "        for line in f:\n",
    "            (key, val) = line.split()\n",
    "            lemmas_dict[str(val)] = key\n",
    "    return lemmas_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(sentence, lemmas_dict):\n",
    "    sentence = ' '.join([lemmas_dict.get(word, word) for word in sentence.split()])\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_reviews(reviews, sw_list, lemmas_dict):\n",
    "    processed_sentences = []\n",
    "    for sent in df['reviewText']:\n",
    "        if not sent != sent:  # check if sent is not nan\n",
    "            sent = sentence_normalization(sent)\n",
    "            sent = remove_stopwords(sent, sw_list)\n",
    "            sent = lemmatize(sent, english_lemmas_dict)\n",
    "            processed_sentences.append(sent)\n",
    "        else:\n",
    "            processed_sentences.append('None')\n",
    "    return processed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_path = '../data'\n",
    "english_lemmas = 'lemmatization-en.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_lemmas_dict = get_lemmas_dict(lemmas_path, english_lemmas)\n",
    "sw_list = get_stop_words('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_reviews = process_reviews(df['reviewText'], sw_list, english_lemmas_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver el efecto del preprocesado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review original: Not a good fit for me. Much too big. I didn't have enough bust to fit into it. Back it went. It might work for someone -- that someone is not me.\n",
      "Review procesada: good fit much enough bust fit back may work someone someone\n"
     ]
    }
   ],
   "source": [
    "print('Review original: {}'.format(df['reviewText'].values[0]))\n",
    "print('Review procesada: {}'.format(processed_reviews[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'processedReview'] = processed_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processedReview'] = df['processedReview'].replace('', np.nan)\n",
    "df = df.dropna(subset=['processedReview'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/corpus.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
